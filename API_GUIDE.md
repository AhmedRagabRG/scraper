# ğŸ—ºï¸ Google Maps Scraper API

API Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ§Øª Ù…Ù† Google Maps Ø¹Ù† Ø·Ø±ÙŠÙ‚ HTTP requests

## ğŸš€ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ù„ÙŠ (Local)

### 1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª

```bash
pip install -r requirements.txt
playwright install chromium
```

### 2. ØªØ´ØºÙŠÙ„ API Server

```bash
python api.py
```

Ø£Ùˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… uvicorn Ù…Ø¨Ø§Ø´Ø±Ø©:

```bash
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

Ø§Ù„Ù€ API Ø³ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰: `http://localhost:8000`

---

## ğŸ³ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Docker

### Ø·Ø±ÙŠÙ‚Ø© 1: Docker Build & Run

```bash
# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ image
docker build -t google-maps-scraper .

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ container
docker run -d \
  --name scraper-api \
  -p 8000:8000 \
  -v $(pwd)/output:/app/output \
  google-maps-scraper
```

### Ø·Ø±ÙŠÙ‚Ø© 2: Docker Compose (Ø§Ù„Ø£Ø³Ù‡Ù„)

```bash
# ØªØ´ØºÙŠÙ„
docker-compose up -d

# Ø¥ÙŠÙ‚Ø§Ù
docker-compose down

# Ø¹Ø±Ø¶ logs
docker-compose logs -f
```

---

## ğŸ“¡ API Endpoints

### 1ï¸âƒ£ **GET /** - Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù€ API

```bash
curl http://localhost:8000/
```

Response:
```json
{
  "name": "Google Maps Scraper API",
  "version": "1.0.0",
  "endpoints": {...}
}
```

---

### 2ï¸âƒ£ **POST /scrape** - Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Scraping

#### Request:

```bash
curl -X POST "http://localhost:8000/scrape" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Coffee Shops in Cairo",
    "max_results": 10,
    "headless": true
  }'
```

#### Response:

```json
{
  "job_id": "a1b2c3d4",
  "status": "pending",
  "message": "Scraping job started. Use /status/a1b2c3d4 to check progress."
}
```

---

### 3ï¸âƒ£ **GET /status/{job_id}** - Ù…ØªØ§Ø¨Ø¹Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ù€ Job

```bash
curl http://localhost:8000/status/a1b2c3d4
```

#### Response (Running):

```json
{
  "job_id": "a1b2c3d4",
  "status": "running",
  "query": "Coffee Shops in Cairo",
  "progress": "Processing 5/10...",
  "created_at": "2026-01-17T12:00:00"
}
```

#### Response (Completed):

```json
{
  "job_id": "a1b2c3d4",
  "status": "completed",
  "query": "Coffee Shops in Cairo",
  "total_results": 10,
  "created_at": "2026-01-17T12:00:00",
  "completed_at": "2026-01-17T12:05:00",
  "download_url": "/download/a1b2c3d4"
}
```

---

### 4ï¸âƒ£ **GET /download/{job_id}** - ØªØ­Ù…ÙŠÙ„ CSV

```bash
curl http://localhost:8000/download/a1b2c3d4 -o results.csv
```

Ø£Ùˆ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„Ù…ØªØµÙØ­:
```
http://localhost:8000/download/a1b2c3d4
```

---

### 5ï¸âƒ£ **GET /results/{job_id}** - Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ JSON

```bash
curl http://localhost:8000/results/a1b2c3d4
```

#### Response:

```json
{
  "job_id": "a1b2c3d4",
  "total_results": 10,
  "results": [
    {
      "business_name": "Coffee Shop",
      "rating": 4.5,
      "review_count": 250,
      "five_star": 180,
      "four_star": 50,
      "three_star": 15,
      "two_star": 3,
      "one_star": 2,
      "phone": "+20123456789",
      "email": "info@coffee.com",
      "website": "https://coffee.com",
      "address": "Cairo, Egypt"
    },
    ...
  ]
}
```

---

### 6ï¸âƒ£ **GET /jobs** - Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ Jobs

```bash
curl http://localhost:8000/jobs
```

---

### 7ï¸âƒ£ **DELETE /job/{job_id}** - Ø­Ø°Ù Job

```bash
curl -X DELETE http://localhost:8000/job/a1b2c3d4
```

---

### 8ï¸âƒ£ **GET /health** - Health Check

```bash
curl http://localhost:8000/health
```

---

## ğŸ“ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©

### Ù…Ø«Ø§Ù„ 1: Scraping Ø¨Ø³ÙŠØ·

```bash
# 1. Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù€ job
RESPONSE=$(curl -s -X POST "http://localhost:8000/scrape" \
  -H "Content-Type: application/json" \
  -d '{"query": "Restaurants in Cairo", "max_results": 20}')

# 2. Ø§Ø³ØªØ®Ø±Ø¬ job_id
JOB_ID=$(echo $RESPONSE | grep -o '"job_id":"[^"]*' | cut -d'"' -f4)

echo "Job ID: $JOB_ID"

# 3. Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ
while true; do
  STATUS=$(curl -s "http://localhost:8000/status/$JOB_ID" | grep -o '"status":"[^"]*' | cut -d'"' -f4)
  echo "Status: $STATUS"
  
  if [ "$STATUS" = "completed" ] || [ "$STATUS" = "failed" ]; then
    break
  fi
  
  sleep 5
done

# 4. Ø­Ù…Ù‘Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
curl "http://localhost:8000/download/$JOB_ID" -o results.csv
echo "Results saved to results.csv"
```

---

### Ù…Ø«Ø§Ù„ 2: Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Python

```python
import requests
import time

# 1. Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù€ scraping
response = requests.post('http://localhost:8000/scrape', json={
    'query': 'Coffee Shops in Cairo',
    'max_results': 10,
    'headless': True
})

job_id = response.json()['job_id']
print(f"Job started: {job_id}")

# 2. Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ
while True:
    status = requests.get(f'http://localhost:8000/status/{job_id}').json()
    print(f"Status: {status['status']} - {status.get('progress', '')}")
    
    if status['status'] in ['completed', 'failed']:
        break
    
    time.sleep(5)

# 3. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ JSON
if status['status'] == 'completed':
    results = requests.get(f'http://localhost:8000/results/{job_id}').json()
    print(f"Total results: {results['total_results']}")
    
    # Ø£Ùˆ Ø­Ù…Ù‘Ù„ CSV
    with open('results.csv', 'wb') as f:
        csv_data = requests.get(f'http://localhost:8000/download/{job_id}')
        f.write(csv_data.content)
    print("CSV downloaded!")
```

---

### Ù…Ø«Ø§Ù„ 3: Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… JavaScript/Node.js

```javascript
const axios = require('axios');
const fs = require('fs');

async function scrapeGoogleMaps() {
  // 1. Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù€ scraping
  const response = await axios.post('http://localhost:8000/scrape', {
    query: 'Hotels in Cairo',
    max_results: 15,
    headless: true
  });
  
  const jobId = response.data.job_id;
  console.log(`Job started: ${jobId}`);
  
  // 2. Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ
  let status;
  while (true) {
    const statusRes = await axios.get(`http://localhost:8000/status/${jobId}`);
    status = statusRes.data;
    console.log(`Status: ${status.status} - ${status.progress || ''}`);
    
    if (status.status === 'completed' || status.status === 'failed') {
      break;
    }
    
    await new Promise(resolve => setTimeout(resolve, 5000));
  }
  
  // 3. Ø­Ù…Ù‘Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
  if (status.status === 'completed') {
    const results = await axios.get(`http://localhost:8000/results/${jobId}`);
    console.log(`Total results: ${results.data.total_results}`);
    
    // Ø­ÙØ¸ CSV
    const csv = await axios.get(`http://localhost:8000/download/${jobId}`, {
      responseType: 'stream'
    });
    csv.data.pipe(fs.createWriteStream('results.csv'));
    console.log('CSV downloaded!');
  }
}

scrapeGoogleMaps();
```

---

## ğŸŒ Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±

### Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 1: Ø¹Ù„Ù‰ VPS Ù…Ø¨Ø§Ø´Ø±Ø©

```bash
# 1. Ø§Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ø³ÙŠØ±ÙØ±
scp -r . user@your-server:/path/to/app

# 2. Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±
cd /path/to/app
docker-compose up -d

# 3. Ø§ÙØªØ­ Port 8000 ÙÙŠ Ø§Ù„Ù€ firewall
sudo ufw allow 8000
```

---

### Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 2: Ø¹Ù„Ù‰ Railway

```bash
# 1. Ø£Ù†Ø´Ø¦ Ø­Ø³Ø§Ø¨ Ø¹Ù„Ù‰ Railway.app
# 2. Ù†ØµÙ‘Ø¨ Railway CLI
npm install -g @railway/cli

# 3. Login
railway login

# 4. Ø£Ù†Ø´Ø¦ project
railway init

# 5. Deploy
railway up
```

Ø£Ø¶Ù `railway.json`:
```json
{
  "build": {
    "builder": "DOCKERFILE"
  },
  "deploy": {
    "startCommand": "python api.py",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

---

### Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 3: Ø¹Ù„Ù‰ Render

1. Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ [render.com](https://render.com)
2. Ø§Ø±Ø¨Ø· GitHub repo
3. Ø§Ø®ØªØ± "Docker"
4. Deploy!

---

## ğŸ”§ Environment Variables

```bash
PORT=8000                    # API port
PYTHONUNBUFFERED=1          # Python output buffering
```

---

## ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©

| Field | Description |
|-------|-------------|
| `business_name` | Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ© |
| `rating` | Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (1-5) |
| `review_count` | Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª |
| `five_star` | Ø¹Ø¯Ø¯ ØªÙ‚ÙŠÙŠÙ…Ø§Øª 5 Ù†Ø¬ÙˆÙ… |
| `four_star` | Ø¹Ø¯Ø¯ ØªÙ‚ÙŠÙŠÙ…Ø§Øª 4 Ù†Ø¬ÙˆÙ… |
| `three_star` | Ø¹Ø¯Ø¯ ØªÙ‚ÙŠÙŠÙ…Ø§Øª 3 Ù†Ø¬ÙˆÙ… |
| `two_star` | Ø¹Ø¯Ø¯ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ù†Ø¬Ù…ØªÙŠÙ† |
| `one_star` | Ø¹Ø¯Ø¯ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ù†Ø¬Ù…Ø© ÙˆØ§Ø­Ø¯Ø© |
| `phone` | Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ |
| `email` | Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ |
| `website` | Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ |
| `address` | Ø§Ù„Ø¹Ù†ÙˆØ§Ù† |

---

## ğŸ› ï¸ Troubleshooting

### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Browser Ù„Ø§ ÙŠÙØªØ­

**Ø§Ù„Ø­Ù„:**
```bash
playwright install chromium
playwright install-deps chromium
```

### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Port Ù…Ø´ØºÙˆÙ„

**Ø§Ù„Ø­Ù„:**
```bash
# ØºÙŠÙ‘Ø± Ø§Ù„Ù€ port
PORT=8080 python api.py
```

### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Timeout errors

**Ø§Ù„Ø­Ù„:**
Ù‚Ù„Ù„ `max_results` Ø£Ùˆ Ø´ØºÙ‘Ù„ Ø¨Ø¯ÙˆÙ† headless Ù„Ù„ØªØµØ­ÙŠØ­.

---

## ğŸ“š Swagger Docs

Ø§ÙØªØ­ ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­:
```
http://localhost:8000/docs
```

Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙˆØ§Ø¬Ù‡Ø© Swagger ØªÙØ§Ø¹Ù„ÙŠØ©! ğŸ¯

---

## ğŸ‰ Done!

Ø§Ù„Ø¢Ù† Ù„Ø¯ÙŠÙƒ API ÙƒØ§Ù…Ù„ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…! ğŸš€
